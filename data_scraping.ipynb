{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests, pickle\n",
    "import numpy as np, pandas as pd\n",
    "from tqdm import notebook\n",
    "from time import sleep\n",
    "import random\n",
    "from random import randint\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def GET_UA():\n",
    "    uastrings = [\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.111 Safari/537.36\",\\\n",
    "                \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0.1500.72 Safari/537.36\",\\\n",
    "                \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10) AppleWebKit/600.1.25 (KHTML, like Gecko) Version/8.0 Safari/600.1.25\",\\\n",
    "                \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:33.0) Gecko/20100101 Firefox/33.0\",\\\n",
    "                \"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.111 Safari/537.36\",\\\n",
    "                \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.111 Safari/537.36\",\\\n",
    "                \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/600.1.17 (KHTML, like Gecko) Version/7.1 Safari/537.85.10\",\\\n",
    "                \"Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko\",\\\n",
    "                \"Mozilla/5.0 (Windows NT 6.3; WOW64; rv:33.0) Gecko/20100101 Firefox/33.0\",\\\n",
    "                \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.104 Safari/537.36\"\\\n",
    "                ]\n",
    " \n",
    "    return random.choice(uastrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    " \n",
    "    headers = {'User-Agent': GET_UA()}\n",
    "    content = None\n",
    " \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        ct = response.headers['Content-Type'].lower().strip()\n",
    " \n",
    "        if 'text/html' in ct:\n",
    "            content = response.content\n",
    "            soup = BeautifulSoup(content, \"html.parser\")\n",
    "        else:\n",
    "            content = response.content\n",
    "            soup = None\n",
    " \n",
    "    except Exception as e:\n",
    "        print(\"Error:\", str(e))\n",
    " \n",
    "    return soup\n",
    " \n",
    " \n",
    "def parse_internal_links(soup, current_page):\n",
    "    return [a['href'].lower().strip() for a in soup.find_all('a', href=True) if urlparse(a['href']).netloc == urlparse(current_page).netloc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Old code that would not work because of timeout? \n",
    "\n",
    "# def get_soup(url):\n",
    "#     #sleep(1)\n",
    "#     page = parse_url(url)\n",
    "    \n",
    "#     return BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_games_links(soup):\n",
    "    games_list = soup.find('div', class_='product_condensed')\n",
    "    links = []\n",
    "    for game in games_list.select('li[class*=\"product game_product\"]'):\n",
    "        links.append(game.a['href'])\n",
    "        \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_game_info(soup):\n",
    "    title = soup.find('div', class_='product_title').find('h1').get_text()\n",
    "    platform = soup.find('span', class_='platform').find('a').get_text().strip()\n",
    "    summary = soup.find('span', class_='blurb blurb_expanded')\n",
    "    if summary is not None:\n",
    "        summary = summary.get_text().strip()\n",
    "    else:\n",
    "        summary = soup.find('span', itemprop='description')\n",
    "        if summary is not None:\n",
    "            summary = summary.get_text().strip()\n",
    "        else:\n",
    "            summary = np.nan\n",
    "    developer = soup.find('li', class_='summary_detail developer')\n",
    "    if developer is not None:\n",
    "        developer = developer.find('span', class_='data').get_text().strip()\n",
    "    else:\n",
    "        developer = np.nan\n",
    "    genre = []\n",
    "    for g in soup.find('li', class_='summary_detail product_genre').find_all('span', class_='data'): \n",
    "        genre.append(g.get_text().strip())\n",
    "    \n",
    "    release_date = soup.find('li', class_='summary_detail release_data')\n",
    "    if release_date is not None: \n",
    "        release_date = release_date.find('span', class_='data').get_text().strip() \n",
    "    else:\n",
    "        release_date = np.nan\n",
    "\n",
    "\n",
    "    rating = soup.find('li', class_='summary_detail product_rating')\n",
    "    if rating is not None: \n",
    "        rating = rating.find('span', class_='data').get_text().strip() \n",
    "    else:\n",
    "        rating = np.nan\n",
    "    \n",
    "    return title, platform, summary, release_date, developer, genre, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_reviews_overview(soup):\n",
    "    overview = soup.find('span', class_='desc').get_text().strip()\n",
    "    reviews_count = soup.find('div', class_='score_distribution')\n",
    "    if reviews_count is not None:\n",
    "        reviews_count = reviews_count.find_all('span', class_='count')\n",
    "        pos = reviews_count[0].get_text().strip()\n",
    "        mixed = reviews_count[1].get_text().strip()\n",
    "        neg = reviews_count[2].get_text().strip()\n",
    "    else:\n",
    "        pos = '0'; mixed = '0'; neg = '0'\n",
    "    \n",
    "    return overview, pos, mixed, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_reviews(soup, category = 'user'):\n",
    "    names = []; dates = []; scores = []\n",
    "    \n",
    "    reviews_list = soup.find('ol', class_=f'reviews {category}_reviews')\n",
    "    if reviews_list is not None:\n",
    "        for review in reviews_list.select(f'li[class*=\"review {category}_review\"]'):\n",
    "            if category == 'user':\n",
    "                names.append(review.find('div', class_='name').get_text().strip())\n",
    "            else:\n",
    "                names.append(review.find('div', class_='source').get_text().strip())\n",
    "            dates.append(review.find('div', class_='date').get_text().strip())\n",
    "            scores.append(review.find('div', class_='review_grade').get_text().strip())\n",
    "\n",
    "    return names, dates, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "letters = ['', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', \n",
    "           'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "console = 'ps4'\n",
    "#console = 'ps5'\n",
    "#console = 'xboxone'\n",
    "#console = 'switch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "games_links = []\n",
    "\n",
    "for letter in letters:\n",
    "    soup = get_soup(f'http://www.metacritic.com/browse/games/title/{console}/{letter}')\n",
    "    games_links += get_games_links(soup)\n",
    "    p = soup.find('ul', class_='pages')\n",
    "    if p is not None: \n",
    "        pages_qty = len(p.find_all('li'))\n",
    "        for page_num in range(1, pages_qty):\n",
    "            soup = get_soup(f'http://www.metacritic.com/browse/games/title/{console}/{letter}?page={page_num}')\n",
    "            games_links += get_games_links(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(games_links, open(f'{console}_games_links', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#games_links = pickle.load(open(f'{console}_games_links', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titles = {}; platforms = {}; summaries = {}; release_dates = {} \n",
    "developers = {}; genres = {}; ratings = {}; meta_scores = {}\n",
    "meta_overviews = {}; meta_pos = {}; meta_mixed = {}\n",
    "meta_neg = {}; critics_names = {}; critics_dates = {}; critics_scores = {}; \n",
    "user_scores = {}; user_overviews = {}\n",
    "user_pos = {}; user_mixed = {}; user_neg = {}; users_names = {}\n",
    "users_dates = {}; users_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#games_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f12548044332472b856b4e01d2e293b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9086 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar = notebook.tqdm(total=len(games_links))\n",
    "\n",
    "for link in games_links:\n",
    "    # game summary section\n",
    "    soup = get_soup(f'http://www.metacritic.com{link}')\n",
    "\n",
    "    # game summary info\n",
    "    title, platform, summary, release_date, developer, genre, rating = get_game_info(soup)\n",
    "    titles[link] = title\n",
    "    platforms[link] = platform\n",
    "    summaries[link] = summary\n",
    "    release_dates[link] = release_date\n",
    "    developers[link] = developer\n",
    "    genres[link] = genre\n",
    "    ratings[link] = rating\n",
    "    \n",
    "    # critics reviews section\n",
    "    soup = get_soup(f'http://www.metacritic.com{link}/critic-reviews')\n",
    "\n",
    "    # critics reviews general info\n",
    "    meta_score = soup.find('span', itemprop='ratingValue')\n",
    "    if meta_score is not None:\n",
    "        meta_scores[link] = meta_score.get_text().strip()\n",
    "    else:\n",
    "        meta_scores[link] = '0'\n",
    "    overview, pos, mixed, neg = get_reviews_overview(soup)\n",
    "    meta_overviews[link] =  overview\n",
    "    meta_pos[link] = pos\n",
    "    meta_mixed[link] = mixed \n",
    "    meta_neg[link] = neg\n",
    "    # critics reviews\n",
    "    names, dates, scores = get_reviews(soup, 'critic')\n",
    "    critics_names[link] = names\n",
    "    critics_dates[link] = dates\n",
    "    critics_scores[link] = scores\n",
    "    \n",
    "    # users reviews section\n",
    "    soup = get_soup(f'http://www.metacritic.com{link}/user-reviews')\n",
    "\n",
    "    # users reviews general info\n",
    "    user_scores[link] = soup.select('div[class*=\"metascore_w user large\"]')[0].get_text().strip()\n",
    "    overview, pos, mixed, neg = get_reviews_overview(soup)\n",
    "    user_overviews[link] =  overview\n",
    "    user_pos[link] = pos\n",
    "    user_mixed[link] = mixed \n",
    "    user_neg[link] = neg\n",
    "    # users reviews\n",
    "    names, dates, scores = get_reviews(soup)\n",
    "    users_names[link] = names\n",
    "    users_dates[link] = dates\n",
    "    users_scores[link] = scores\n",
    "\n",
    "    # p = soup.find('ul', class_='pages')\n",
    "    # if p is not None: \n",
    "    #     pages_qty = len(p.find_all('li'))\n",
    "    #     for page_num in range(1, pages_qty):\n",
    "    #         sleep(randint(1,3))\n",
    "    #         soup = get_soup(f'http://www.metacritic.com{link}/user-reviews?page={page_num}')\n",
    "\n",
    "    #         names, dates, scores = get_reviews(soup)\n",
    "    #         users_names[link] += names\n",
    "    #         users_dates[link] += dates\n",
    "    #         users_scores[link] += scores\n",
    "    \n",
    "    bar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/game/xbox-one/f1-2016\n"
     ]
    }
   ],
   "source": [
    "# Was used to debug\n",
    "\n",
    "# link=games_links[1]\n",
    "# print(link)\n",
    "# soup = get_soup(f'http://www.metacritic.com{link}')\n",
    "# #print(soup.prettify())\n",
    "# title = soup.find('div', class_='product_title').find('h1').get_text()\n",
    "# overview = soup.find('span', class_='desc').get_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'title': titles, 'platform': platforms, 'summary': summaries, \n",
    "                   'release_date': release_dates, 'developer': developers, 'genre': genres, \n",
    "                   'rating': ratings, 'meta_score': meta_scores, 'meta_overview': meta_overviews,\n",
    "                   'meta_pos': meta_pos, 'meta_mixed': meta_mixed, 'meta_neg': meta_neg, \n",
    "                   'user_score': user_scores, 'user_overview': user_overviews, 'user_pos': user_pos, \n",
    "                   'user_mixed': user_mixed, 'user_neg': user_neg },\n",
    "                   columns=['title', 'platform', 'developer', 'genre', 'rating', 'release_date',\n",
    "                            'summary', 'meta_score', 'meta_overview', 'meta_pos', 'meta_mixed', \n",
    "                            'meta_neg', 'user_score', 'user_overview', 'user_pos', 'user_mixed', \n",
    "                            'user_neg']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(f'{console}_games.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_reviews_df(critics_dict, dates_dict, scores_dict):\n",
    "    critics = []; dates = []; scores = []; texts = []; games = []; plats = []\n",
    "    for k in critics_dict:\n",
    "        critics += critics_dict[k]\n",
    "        dates += dates_dict[k]\n",
    "        scores += scores_dict[k]\n",
    "        games += [titles[k]] * len(critics_dict[k])\n",
    "        plats += [platforms[k]] * len(critics_dict[k])\n",
    "    \n",
    "    return pd.DataFrame({'critic': critics, 'date': dates, 'score': scores, 'title': games, 'platform': plats},\n",
    "                         columns = ['score', 'critic', 'date', 'title', 'platform'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = create_reviews_df(critics_names, critics_dates, critics_scores)\n",
    "df.to_csv(f'{console}_meta_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = create_reviews_df(users_names, users_dates, users_scores)\n",
    "df.to_csv(f'{console}_user_reviews.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
